{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, open this experiment on Trovi:\n",
    "\n",
    "-   Use this link: [Large-scale model training on Chameleon](https://chameleoncloud.org/experiment/share/39a536c6-6070-4ccf-9e91-bc47be9a94af) on Trovi\n",
    "-   Then, click “Launch on Chameleon”. This will start a new Jupyter server for you, with the experiment materials already in it.\n",
    "\n",
    "You will see several notebooks inside the `llm-chi` directory - look for the one titled `1_create_server.ipynb`. Open this notebook and continue there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring up a GPU server\n",
    "\n",
    "At the beginning of the lease time, we will bring up our GPU server. We will use the `python-chi` Python API to Chameleon to provision our server.\n",
    "\n",
    "We will execute the cells in this notebook inside the Chameleon Jupyter environment.\n",
    "\n",
    "Run the following cell, and make sure the correct project is selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010f0178cb334528ac15baca4956223b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Project', options=('CHI-251409',), value='CHI-251409'), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3405b6222ed7486693afd9f190970fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Site', options=('CHI@TACC', 'CHI@UC', 'CHI@EVL', 'CHI@NCAR', 'CHI@…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chi import server, context, lease\n",
    "import os\n",
    "\n",
    "context.version = \"1.0\" \n",
    "context.choose_project()\n",
    "context.choose_site(default=\"CHI@TACC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the string in the following cell to reflect the name of *your* lease (**with your own net ID**), then run it to get your lease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485c3576fa51452c957c21e7784ab55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n        <h2>Lease Details</h2>\\n        <table>\\n            <tr><th>Name</th><td>project17_liq2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lease Details:\n",
      "Name: project17_liq2\n",
      "ID: 790bb75d-f20e-4241-8221-f8516f086c4e\n",
      "Status: PENDING\n",
      "Start Date: 2025-05-11 21:00:00\n",
      "End Date: 2025-05-12 02:30:00\n",
      "User ID: 80faa74e719af4d9b94f9792fcb80236a036e83f75b2d23667c917eda74a7179\n",
      "Project ID: d3c6e101843a4ba79e665ebf59b521a2\n",
      "\n",
      "Node Reservations:\n",
      "ID: 2e8b8d05-4784-4849-ae79-dd4131417816, Status: pending, Min: 1, Max: 1\n",
      "\n",
      "Floating IP Reservations:\n",
      "\n",
      "Network Reservations:\n",
      "\n",
      "Events:\n"
     ]
    }
   ],
   "source": [
    "l = lease.get_lease(f\"project17_liq2\") # or llm_single_netID, or llm_multi_netID\n",
    "l.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status should show as “ACTIVE” now that we are past the lease start time.\n",
    "\n",
    "The rest of this notebook can be executed without any interactions from you, so at this point, you can save time by clicking on this cell, then selecting Run \\> Run Selected Cell and All Below from the Jupyter menu.\n",
    "\n",
    "As the notebook executes, monitor its progress to make sure it does not get stuck on any execution error, and also to see what it is doing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the lease to bring up a server with the `CC-Ubuntu24.04-CUDA` disk image. (Note that the reservation information is passed when we create the instance!) This will take up to 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server node-llm-rh3884_nyu_edu's status to become ACTIVE. This typically takes 10 minutes, but can take up to 20 minutes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b22c2ff20c34d8b9046a63740870107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value=''), IntProgress(value=0, bar_style='success')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server has moved to status ERROR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style='border-collapse: collapse; width: 100%;'><tr style='background-color: #f2f2f2;'><th style='border: 1px solid #ddd; padding: 8px;'>Attribute</th><th style='border: 1px solid #ddd; padding: 8px;'>node-llm-rh3884_nyu_edu</th></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Id</td><td style='border: 1px solid #ddd; padding: 8px;'>722c9391-3ece-47a4-9544-612bec113abe</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Status</td><td style='border: 1px solid #ddd; padding: 8px;'>ERROR</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Image Name</td><td style='border: 1px solid #ddd; padding: 8px;'>CC-Ubuntu24.04-CUDA</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Flavor Name</td><td style='border: 1px solid #ddd; padding: 8px;'>baremetal</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Addresses</td><td style='border: 1px solid #ddd; padding: 8px;'></td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Network Name</td><td style='border: 1px solid #ddd; padding: 8px;'>sharednet1</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Created At</td><td style='border: 1px solid #ddd; padding: 8px;'>2025-05-11T20:07:50Z</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Keypair</td><td style='border: 1px solid #ddd; padding: 8px;'>trovi-b104fa3</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Reservation Id</td><td style='border: 1px solid #ddd; padding: 8px;'>2e8b8d05-4784-4849-ae79-dd4131417816</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Host Id</td><td style='border: 1px solid #ddd; padding: 8px;'></td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Host Status</td><td style='border: 1px solid #ddd; padding: 8px;'>None</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Hypervisor Hostname</td><td style='border: 1px solid #ddd; padding: 8px;'>None</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Is Locked</td><td style='border: 1px solid #ddd; padding: 8px;'>False</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "username = os.getenv('USER') # all exp resources will have this prefix\n",
    "s = server.Server(\n",
    "    f\"node-llm-{username}\", \n",
    "    reservation_id=l.node_reservations[0][\"id\"],\n",
    "    image_name=\"CC-Ubuntu24.04-CUDA\"\n",
    ")\n",
    "s.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: security groups are not used at Chameleon bare metal sites, so we do not have to configure any security groups on this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we’ll associate a floating IP with the instance, so that we can access it over SSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ResourceError",
     "evalue": "None of the ports can route to floating ip 129.114.108.211 on server c58b81fe-d5fd-4ba6-9fea-f8690b670326",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126/831154080.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massociate_floating_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/chi/server.py\u001b[0m in \u001b[0;36massociate_floating_ip\u001b[0;34m(self, fip, port_id)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \"\"\"\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0massociate_floating_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/chi/server.py\u001b[0m in \u001b[0;36massociate_floating_ip\u001b[0;34m(server_id, floating_ip_address, port_id)\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0mfloating_ip_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloating_ip_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"floating_ip_address\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of the ports can route to floating ip {floating_ip_address} on server {server_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceError\u001b[0m: None of the ports can route to floating ip 129.114.108.211 on server c58b81fe-d5fd-4ba6-9fea-f8690b670326"
     ]
    }
   ],
   "source": [
    "s.associate_floating_ip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.refresh()\n",
    "s.check_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.refresh()\n",
    "s.show(type=\"widget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Docker with NVIDIA container toolkit\n",
    "\n",
    "To use common deep learning frameworks like Tensorflow or PyTorch, we can run containers that have all the prerequisite libraries necessary for these frameworks. Here, we will set up the container framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'rsplit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126/2263180142.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"curl -sSL https://get.docker.com/ | sudo sh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sudo groupadd -f docker; sudo usermod -aG docker $USER\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"docker run hello-world\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/chi/server.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mshell\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0mto\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssh_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/chi/server.py\u001b[0m in \u001b[0;36mssh_connection\u001b[0;34m(self, user, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"connect_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key_filename\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_floating_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Default policy is to reject unknown hosts - for our use-case,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# printing a warning is probably enough, given the host is almost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/fabric/connection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, user, port, config, gateway, forward_agent, connect_timeout, connect_kwargs, inline_ssh_env)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# TODO: i.e. what is the lib use case here (and honestly in invoke too)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mshorthand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderive_shorthand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshorthand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"You supplied the {} via both shorthand and kwarg! Please pick one.\"\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/fabric/connection.py\u001b[0m in \u001b[0;36mderive_shorthand\u001b[0;34m(self, host_string)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;31m# backwards compatibility and because it seems plausible we may want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;31m# modify behavior later, using eg config or other attributes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mderive_shorthand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/fabric/connection.py\u001b[0m in \u001b[0;36mderive_shorthand\u001b[0;34m(host_string)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mderive_shorthand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0muser_hostport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhost_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"@\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mhostport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_hostport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_hostport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muser_hostport\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muser_hostport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'rsplit'"
     ]
    }
   ],
   "source": [
    "s.execute(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
    "s.execute(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")\n",
    "s.execute(\"docker run hello-world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also install the NVIDIA container toolkit, with which we can access GPUs from inside our containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://nvidia.github.io/libnvidia-container/stable/deb/$(ARCH) /\n",
      "#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://nvidia.github.io/libnvidia-container/experimental/deb/$(ARCH) /\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://download.docker.com/linux/ubuntu noble InRelease\n",
      "Get:2 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease [1477 B]\n",
      "Get:3 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  Packages [18.6 kB]\n",
      "Get:4 http://nova.clouds.archive.ubuntu.com/ubuntu noble InRelease [256 kB]\n",
      "Hit:5 http://security.ubuntu.com/ubuntu noble-security InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  InRelease\n",
      "Get:7 http://nova.clouds.archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Get:8 http://nova.clouds.archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]\n",
      "Fetched 528 kB in 1s (477 kB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "4 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  libnvidia-container-tools libnvidia-container1 nvidia-container-toolkit-base\n",
      "The following NEW packages will be installed:\n",
      "  libnvidia-container-tools libnvidia-container1 nvidia-container-toolkit\n",
      "  nvidia-container-toolkit-base\n",
      "0 upgraded, 4 newly installed, 0 to remove and 4 not upgraded.\n",
      "Need to get 5849 kB of archives.\n",
      "After this operation, 27.9 MB of additional disk space will be used.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  libnvidia-container1 1.17.6-1 [926 kB]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  libnvidia-container-tools 1.17.6-1 [21.5 kB]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  nvidia-container-toolkit-base 1.17.6-1 [3711 kB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  nvidia-container-toolkit 1.17.6-1 [1191 kB]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 5849 kB in 2s (2860 kB/s)\n",
      "Selecting previously unselected package libnvidia-container1:amd64.\n",
      "(Reading database ... 113813 files and directories currently installed.)\n",
      "Preparing to unpack .../libnvidia-container1_1.17.6-1_amd64.deb ...\n",
      "Unpacking libnvidia-container1:amd64 (1.17.6-1) ...\n",
      "Selecting previously unselected package libnvidia-container-tools.\n",
      "Preparing to unpack .../libnvidia-container-tools_1.17.6-1_amd64.deb ...\n",
      "Unpacking libnvidia-container-tools (1.17.6-1) ...\n",
      "Selecting previously unselected package nvidia-container-toolkit-base.\n",
      "Preparing to unpack .../nvidia-container-toolkit-base_1.17.6-1_amd64.deb ...\n",
      "Unpacking nvidia-container-toolkit-base (1.17.6-1) ...\n",
      "Selecting previously unselected package nvidia-container-toolkit.\n",
      "Preparing to unpack .../nvidia-container-toolkit_1.17.6-1_amd64.deb ...\n",
      "Unpacking nvidia-container-toolkit (1.17.6-1) ...\n",
      "Setting up nvidia-container-toolkit-base (1.17.6-1) ...\n",
      "Setting up libnvidia-container1:amd64 (1.17.6-1) ...\n",
      "Setting up libnvidia-container-tools (1.17.6-1) ...\n",
      "Setting up nvidia-container-toolkit (1.17.6-1) ...\n",
      "Processing triggers for libc-bin (2.39-0ubuntu8.4) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "\n",
      "Running kernel seems to be up-to-date.\n",
      "\n",
      "The processor microcode seems to be up-to-date.\n",
      "\n",
      "No services need to be restarted.\n",
      "\n",
      "No containers need to be restarted.\n",
      "\n",
      "No user sessions are running outdated binaries.\n",
      "\n",
      "No VM guests are running outdated hypervisor (qemu) binaries on this host.\n",
      "time=\"2025-05-10T13:19:48Z\" level=info msg=\"Config file does not exist; using empty config\"\n",
      "time=\"2025-05-10T13:19:48Z\" level=info msg=\"Wrote updated config to /etc/docker/daemon.json\"\n",
      "time=\"2025-05-10T13:19:48Z\" level=info msg=\"It is recommended that docker daemon be restarted.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='sudo systemctl restart docker' exited=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get NVIDIA container toolkit \n",
    "s.execute(\"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
    "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
    "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
    "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\")\n",
    "s.execute(\"sudo apt update\")\n",
    "s.execute(\"sudo apt-get install -y nvidia-container-toolkit\")\n",
    "s.execute(\"sudo nvidia-ctk runtime configure --runtime=docker\")\n",
    "s.execute(\"sudo systemctl restart docker\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we will verify that we can see our NVIDIA GPUs from inside a container, by passing `--gpus-all`. (The `-rm` flag says to clean up the container and remove its filesystem when it finishes running.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to find image 'ubuntu:latest' locally\n",
      "latest: Pulling from library/ubuntu\n",
      "0622fac788ed: Pulling fs layer\n",
      "0622fac788ed: Verifying Checksum\n",
      "0622fac788ed: Download complete\n",
      "0622fac788ed: Pull complete\n",
      "Digest: sha256:6015f66923d7afbc53558d7ccffd325d43b4e249f41a6e93eef074c9505d2233\n",
      "Status: Downloaded newer image for ubuntu:latest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 10 13:19:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB          Off |   00000000:97:00.0 Off |                    0 |\n",
      "| N/A   24C    P0             33W /  250W |       1MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCIE-40GB          Off |   00000000:99:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             32W /  250W |       1MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='docker run --rm --gpus all ubuntu nvidia-smi' exited=0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"docker run --rm --gpus all ubuntu nvidia-smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s pull the actual container images that we are going to use,\n",
    "\n",
    "-   For the “Single GPU” section: a Jupyter notebook server with PyTorch and CUDA libraries\n",
    "-   For the “Multiple GPU” section: a PyTorch image with NVIDIA developer tools, which we’ll need in order to install DeepSpeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull container for “Multiple GPU” section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1-cuda12.4-cudnn9-devel: Pulling from pytorch/pytorch\n",
      "7021d1b70935: Pulling fs layer\n",
      "0d6448aff889: Pulling fs layer\n",
      "0a7674e3e8fe: Pulling fs layer\n",
      "b71b637b97c5: Pulling fs layer\n",
      "56dc85502937: Pulling fs layer\n",
      "ec6d5f6c9ed9: Pulling fs layer\n",
      "47b8539d532f: Pulling fs layer\n",
      "fd9cc1ad8dee: Pulling fs layer\n",
      "83525caeeb35: Pulling fs layer\n",
      "8e79813a7b9d: Pulling fs layer\n",
      "312a542960e3: Pulling fs layer\n",
      "0acb777129a5: Pulling fs layer\n",
      "e725174e3835: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "3093b7e1cc2f: Pulling fs layer\n",
      "47b8539d532f: Waiting\n",
      "fd9cc1ad8dee: Waiting\n",
      "312a542960e3: Waiting\n",
      "83525caeeb35: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "56dc85502937: Waiting\n",
      "ec6d5f6c9ed9: Waiting\n",
      "e725174e3835: Waiting\n",
      "0acb777129a5: Waiting\n",
      "8e79813a7b9d: Waiting\n",
      "b71b637b97c5: Waiting\n",
      "0d6448aff889: Verifying Checksum\n",
      "0d6448aff889: Download complete\n",
      "b71b637b97c5: Verifying Checksum\n",
      "b71b637b97c5: Download complete\n",
      "0a7674e3e8fe: Verifying Checksum\n",
      "0a7674e3e8fe: Download complete\n",
      "7021d1b70935: Verifying Checksum\n",
      "7021d1b70935: Download complete\n",
      "56dc85502937: Download complete\n",
      "47b8539d532f: Verifying Checksum\n",
      "47b8539d532f: Download complete\n",
      "fd9cc1ad8dee: Download complete\n",
      "83525caeeb35: Download complete\n",
      "312a542960e3: Verifying Checksum\n",
      "312a542960e3: Download complete\n",
      "0acb777129a5: Verifying Checksum\n",
      "0acb777129a5: Download complete\n",
      "7021d1b70935: Pull complete\n",
      "0d6448aff889: Pull complete\n",
      "0a7674e3e8fe: Pull complete\n",
      "b71b637b97c5: Pull complete\n",
      "56dc85502937: Pull complete\n",
      "ec6d5f6c9ed9: Verifying Checksum\n",
      "ec6d5f6c9ed9: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "3093b7e1cc2f: Download complete\n",
      "e725174e3835: Verifying Checksum\n",
      "e725174e3835: Download complete\n",
      "8e79813a7b9d: Verifying Checksum\n",
      "8e79813a7b9d: Download complete\n",
      "ec6d5f6c9ed9: Pull complete\n",
      "47b8539d532f: Pull complete\n",
      "fd9cc1ad8dee: Pull complete\n",
      "83525caeeb35: Pull complete\n",
      "8e79813a7b9d: Pull complete\n",
      "312a542960e3: Pull complete\n",
      "0acb777129a5: Pull complete\n",
      "e725174e3835: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "3093b7e1cc2f: Pull complete\n",
      "Digest: sha256:14611869895df612b7b07227d5925f30ec3cd6673bad58ce3d84ed107950e014\n",
      "Status: Downloaded newer image for pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel\n",
      "docker.io/pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='docker pull pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel' exited=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"docker pull pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and let’s also install some software on the host that we’ll use in the “Multiple GPU” section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://download.docker.com/linux/ubuntu noble InRelease\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  InRelease\n",
      "Hit:3 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease\n",
      "Get:4 http://nova.clouds.archive.ubuntu.com/ubuntu noble InRelease [256 kB]\n",
      "Hit:5 http://security.ubuntu.com/ubuntu noble-security InRelease\n",
      "Hit:6 http://nova.clouds.archive.ubuntu.com/ubuntu noble-updates InRelease\n",
      "Hit:7 http://nova.clouds.archive.ubuntu.com/ubuntu noble-backports InRelease\n",
      "Fetched 256 kB in 1s (412 kB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "4 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  nvtop\n",
      "0 upgraded, 1 newly installed, 0 to remove and 4 not upgraded.\n",
      "Need to get 62.8 kB of archives.\n",
      "After this operation, 180 kB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu noble/multiverse amd64 nvtop amd64 3.0.2-1 [62.8 kB]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 62.8 kB in 0s (126 kB/s)\n",
      "Selecting previously unselected package nvtop.\n",
      "(Reading database ... 113837 files and directories currently installed.)\n",
      "Preparing to unpack .../nvtop_3.0.2-1_amd64.deb ...\n",
      "Unpacking nvtop (3.0.2-1) ...\n",
      "Setting up nvtop (3.0.2-1) ...\n",
      "Processing triggers for man-db (2.12.0-4build2) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "\n",
      "Running kernel seems to be up-to-date.\n",
      "\n",
      "The processor microcode seems to be up-to-date.\n",
      "\n",
      "No services need to be restarted.\n",
      "\n",
      "No containers need to be restarted.\n",
      "\n",
      "No user sessions are running outdated binaries.\n",
      "\n",
      "No VM guests are running outdated hypervisor (qemu) binaries on this host.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='sudo apt update; sudo apt -y install nvtop' exited=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"sudo apt update; sudo apt -y install nvtop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'mlops_test_raghu'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='git clone https://github.com/RaghuHemadri/mlops_test_raghu.git' exited=0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"git clone https://github.com/RaghuHemadri/mlops_test_raghu.git\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose can now delegate builds to bake for better performance.\n",
      " To do so, set COMPOSE_BAKE=true.\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [ray-worker-2 internal] load build definition from Dockerfile.ray-worker\n",
      "#1 transferring dockerfile: 191B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [ray-worker-1 internal] load build definition from Dockerfile.ray-worker\n",
      "#2 transferring dockerfile: 191B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [jupyter internal] load build definition from Dockerfile.jupyter-ray\n",
      "#3 transferring dockerfile: 340B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [ray-worker-1 internal] load metadata for docker.io/rayproject/ray:2.42.1\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [ray-worker-2 internal] load .dockerignore\n",
      "#5 transferring context: 2B done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ray-worker-1 internal] load .dockerignore\n",
      "#6 transferring context: 2B done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [ray-worker-1 1/2] FROM docker.io/rayproject/ray:2.42.1\n",
      "#7 DONE 0.0s\n",
      "\n",
      "#8 [ray-worker-1 2/2] RUN pip install --no-cache-dir     torch     \"lightning<2.5.0.post0\"     \"litgpt[all]==0.5.7\"     mlflow\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ray-worker-2] exporting to image\n",
      "#9 exporting layers done\n",
      "#9 writing image sha256:36126599f07aa0e9384a46e34af415cde7e9446399e6ebc9078808da2d44d115 done\n",
      "#9 naming to docker.io/library/ray_cluster-ray-worker-2 done\n",
      "#9 DONE 0.0s\n",
      "\n",
      "#10 [ray-worker-1] exporting to image\n",
      "#10 exporting layers done\n",
      "#10 writing image sha256:5c4974055e4ebae5b4d4e755aed76682000288ac096fb0964dd14e254e065b94 done\n",
      "#10 naming to docker.io/library/ray_cluster-ray-worker-1 done\n",
      "#10 DONE 0.0s\n",
      "\n",
      "#11 [ray-worker-2] resolving provenance for metadata file\n",
      "#11 DONE 0.0s\n",
      "\n",
      "#12 [ray-worker-1] resolving provenance for metadata file\n",
      "#12 DONE 0.0s\n",
      "\n",
      "#13 [jupyter internal] load metadata for quay.io/jupyter/pytorch-notebook:latest\n",
      "#13 DONE 0.3s\n",
      "\n",
      "#14 [jupyter internal] load .dockerignore\n",
      "#14 transferring context: 2B done\n",
      "#14 DONE 0.0s\n",
      "\n",
      "#15 [jupyter 1/2] FROM quay.io/jupyter/pytorch-notebook:latest@sha256:81385abbee70ba638b48ce4607f72b84d2207de31b1fb253f4237c5eee1958d4\n",
      "#15 DONE 0.0s\n",
      "\n",
      "#16 [jupyter 2/2] RUN pip install --no-cache-dir     torch torchvision     \"lightning<2.5.0.post0\"     \"litgpt[all]==0.5.7\"     ray==2.42.1     mlflow &&     fix-permissions \"/opt/conda\" &&     fix-permissions \"/home/jovyan\"\n",
      "#16 CACHED\n",
      "\n",
      "#17 [jupyter] exporting to image\n",
      "#17 exporting layers done\n",
      "#17 writing image sha256:e001451377291ca60b33ad66127c487a44cff5e83610c5604d73fa7e0142a174 done\n",
      "#17 naming to docker.io/library/ray_cluster-jupyter done\n",
      "#17 DONE 0.0s\n",
      "\n",
      "#18 [jupyter] resolving provenance for metadata file\n",
      "#18 DONE 0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " jupyter  Built\n",
      " ray-worker-1  Built\n",
      " ray-worker-2  Built\n",
      " Container ray-head  Created\n",
      " Container postgres  Created\n",
      " Container minio  Created\n",
      " Container jupyter-ray  Created\n",
      " Container ray_cluster-minio-create-bucket-1  Created\n",
      " Container grafana  Created\n",
      " Container mlflow  Created\n",
      " Container ray-worker-1  Created\n",
      " Container ray-worker-2  Created\n",
      " Container postgres  Starting\n",
      " Container ray-head  Starting\n",
      " Container minio  Starting\n",
      " Container minio  Started\n",
      " Container minio  Waiting\n",
      " Container postgres  Started\n",
      " Container ray-head  Started\n",
      " Container jupyter-ray  Starting\n",
      " Container grafana  Starting\n",
      " Container ray-worker-1  Starting\n",
      " Container ray-worker-2  Starting\n",
      " Container jupyter-ray  Started\n",
      " Container grafana  Started\n",
      " Container ray-worker-1  Started\n",
      " Container ray-worker-2  Started\n",
      " Container minio  Healthy\n",
      " Container ray_cluster-minio-create-bucket-1  Starting\n",
      " Container ray_cluster-minio-create-bucket-1  Started\n",
      " Container mlflow  Starting\n",
      " Container mlflow  Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                           COMMAND                   CREATED       STATUS                            PORTS                                                                                                                                                                                                                             NAMES\n",
      "f99625091163   ray_cluster-ray-worker-2        \"ray start --address…\"    3 hours ago   Up 4 seconds                                                                                                                                                                                                                                                        ray-worker-2\n",
      "ab3594408a98   ray_cluster-jupyter             \"tini -g -- start.sh…\"    3 hours ago   Up 4 seconds (health: starting)   0.0.0.0:8888->8888/tcp, [::]:8888->8888/tcp                                                                                                                                                                                       jupyter-ray\n",
      "6bca5aeec379   ray_cluster-ray-worker-1        \"ray start --address…\"    3 hours ago   Up 4 seconds                                                                                                                                                                                                                                                        ray-worker-1\n",
      "b8d7b06f7a69   rayproject/ray:2.42.1           \"/bin/sh -c '\\nmkdir …\"   3 hours ago   Up 4 seconds                      0.0.0.0:6379->6379/tcp, [::]:6379->6379/tcp, 0.0.0.0:8080->8080/tcp, [::]:8080->8080/tcp, 0.0.0.0:8090->8090/tcp, [::]:8090->8090/tcp, 0.0.0.0:8265->8265/tcp, [::]:8265->8265/tcp, 0.0.0.0:9090->9090/tcp, [::]:9090->9090/tcp   ray-head\n",
      "3a83eb89250b   ghcr.io/mlflow/mlflow:v2.20.2   \"/bin/sh -c 'pip ins…\"    3 hours ago   Up 2 seconds                      0.0.0.0:8000->8000/tcp, [::]:8000->8000/tcp                                                                                                                                                                                       mlflow\n",
      "d25a658b9a9c   grafana/grafana:latest          \"/bin/sh -c '\\n# Wait…\"   3 hours ago   Up 4 seconds                      0.0.0.0:3000->3000/tcp, [::]:3000->3000/tcp                                                                                                                                                                                       grafana\n",
      "c35d6cc07c67   postgres:latest                 \"docker-entrypoint.s…\"    3 hours ago   Up 4 seconds                      0.0.0.0:5432->5432/tcp, [::]:5432->5432/tcp                                                                                                                                                                                       postgres\n",
      "7adfcfdcfddb   minio/minio                     \"/usr/bin/docker-ent…\"    3 hours ago   Up 4 seconds (healthy)            0.0.0.0:9000-9001->9000-9001/tcp, [::]:9000-9001->9000-9001/tcp                                                                                                                                                                   minio\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='docker ps' exited=0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"export HOST_IP=$(curl --silent http://169.254.169.254/latest/meta-data/public-ipv4); cd mlops_test_raghu; docker compose -f docker-compose-ray.yaml up --build -d\")\n",
    "s.execute(\"docker ps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result cmd='cd mlops_test_raghu; sudo chmod -R 777 workspace' exited=0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"cd mlops_test_raghu; sudo chmod -R 777 workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result cmd='cd mlops_test_raghu; sudo cp train_ray.py workspace/train_ray.py; sudo cp ray_requirements.txt workspace/ray_requirements.txt; sudo cp ray_runtime.json workspace/ray_runtime.json' exited=0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"cd mlops_test_raghu; sudo cp train.py workspace/train.py; sudo cp retrain.py workspace/retrain.py; sudo cp raytune.py workspace/raytune.py; sudo cp ray_requirements.txt workspace/ray_requirements.txt; sudo cp ray_runtime.json workspace/ray_runtime.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entered start.sh with args: start-notebook.py\n",
      "Running hooks in: /usr/local/bin/start-notebook.d as uid: 1000 gid: 100\n",
      "Done running hooks in: /usr/local/bin/start-notebook.d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: jupyter lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running hooks in: /usr/local/bin/before-notebook.d as uid: 1000 gid: 100\n",
      "Sourcing shell script: /usr/local/bin/before-notebook.d/10activate-conda-env.sh\n",
      "Done running hooks in: /usr/local/bin/before-notebook.d\n",
      "Executing the command: start-notebook.py\n",
      "[I 2025-05-10 14:02:35.726 ServerApp] jupyter_lsp | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.729 ServerApp] jupyter_server_mathjax | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.731 ServerApp] jupyter_server_terminals | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.735 ServerApp] jupyterlab | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.735 ServerApp] jupyterlab_git | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.737 ServerApp] nbclassic | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.737 ServerApp] nbdime | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.740 ServerApp] notebook | extension was successfully linked.\n",
      "[I 2025-05-10 14:02:35.742 ServerApp] Writing Jupyter server cookie secret to /home/jovyan/.local/share/jupyter/runtime/jupyter_cookie_secret\n",
      "[I 2025-05-10 14:02:35.924 ServerApp] notebook_shim | extension was successfully linked.\n",
      "[W 2025-05-10 14:02:35.939 ServerApp] WARNING: The Jupyter server is listening on all IP addresses and not using encryption. This is not recommended.\n",
      "[I 2025-05-10 14:02:35.939 ServerApp] notebook_shim | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:35.963 ServerApp] jupyter_lsp | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:35.963 ServerApp] jupyter_server_mathjax | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:35.964 ServerApp] jupyter_server_terminals | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:35.966 LabApp] JupyterLab extension loaded from /opt/conda/lib/python3.12/site-packages/jupyterlab\n",
      "[I 2025-05-10 14:02:35.967 LabApp] JupyterLab application directory is /opt/conda/share/jupyter/lab\n",
      "[I 2025-05-10 14:02:35.967 LabApp] Extension Manager is 'pypi'.\n",
      "[I 2025-05-10 14:02:36.002 ServerApp] jupyterlab | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:36.005 ServerApp] jupyterlab_git | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:36.008 ServerApp] nbclassic | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:36.050 ServerApp] nbdime | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:36.054 ServerApp] notebook | extension was successfully loaded.\n",
      "[I 2025-05-10 14:02:36.085 ServerApp] Serving notebooks from local directory: /home/jovyan\n",
      "[I 2025-05-10 14:02:36.085 ServerApp] Jupyter Server 2.15.0 is running at:\n",
      "[I 2025-05-10 14:02:36.085 ServerApp] http://localhost:8888/lab?token=243112237f14ceae7ebc03ac78a5808bdec40d85b00c05c6\n",
      "[I 2025-05-10 14:02:36.085 ServerApp]     http://127.0.0.1:8888/lab?token=243112237f14ceae7ebc03ac78a5808bdec40d85b00c05c6\n",
      "[I 2025-05-10 14:02:36.085 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "[C 2025-05-10 14:02:36.087 ServerApp]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _   _          _      _\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \n",
      "    \n",
      "    To access the server, open this file in a browser:\n",
      "        file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html\n",
      "    Or copy and paste one of these URLs:\n",
      "        http://localhost:8888/lab?token=243112237f14ceae7ebc03ac78a5808bdec40d85b00c05c6\n",
      "        http://127.0.0.1:8888/lab?token=243112237f14ceae7ebc03ac78a5808bdec40d85b00c05c6\n",
      "[I 2025-05-10 14:02:36.162 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\n",
      "[W 2025-05-10 14:02:45.851 ServerApp] Clearing invalid/expired login cookie username-129-114-109-173-8888\n",
      "[W 2025-05-10 14:02:45.865 TerminalsExtensionApp] 403 GET /terminals/websocket/1 (@216.165.95.86) 14.47ms referer=None\n",
      "[W 2025-05-10 14:02:46.870 ServerApp] Clearing invalid/expired login cookie username-129-114-109-173-8888\n",
      "[W 2025-05-10 14:02:46.871 ServerApp] Couldn't authenticate WebSocket connection\n",
      "[W 2025-05-10 14:02:46.871 ServerApp] 403 GET /api/events/subscribe (@216.165.95.86) 1.22ms referer=None\n",
      "[W 2025-05-10 14:02:48.662 ServerApp] Clearing invalid/expired login cookie username-129-114-109-173-8888\n",
      "[W 2025-05-10 14:02:48.662 ServerApp] Couldn't authenticate WebSocket connection\n",
      "[W 2025-05-10 14:02:48.663 ServerApp] 403 GET /api/events/subscribe (@216.165.95.86) 1.06ms referer=None\n",
      "[W 2025-05-10 14:02:48.663 ServerApp] Clearing invalid/expired login cookie username-129-114-109-173-8888\n",
      "[I 2025-05-10 14:02:48.663 LabApp] 302 GET /lab/tree/work (@216.165.95.86) 1.24ms\n",
      "[I 2025-05-10 14:03:02.951 ServerApp] User 7cabbe1703584415a46046e155fc6c58 logged in.\n",
      "[I 2025-05-10 14:03:02.952 ServerApp] 302 POST /login?next=%2Flab%2Ftree%2Fwork (7"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | | | |_ __  __| |__ _| |_ ___\n",
      " | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "  \\___/| .__/\\__,_\\__,_|\\__\\___|\n",
      "       |_|\n",
      "\n",
      "Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions.\n",
      "\n",
      "https://jupyter-notebook.readthedocs.io/en/latest/migrate_to_notebook7.html\n",
      "\n",
      "Please note that updating to Notebook 7 might break some of your extensions.\n",
      "\n",
      "Executing: jupyter lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cabbe1703584415a46046e155fc6c58@216.165.95.86) 1.04ms\n",
      "[W 2025-05-10 14:03:04.315 LabApp] Could not determine jupyterlab build status without nodejs\n",
      "[I 2025-05-10 14:03:07.819 ServerApp] New terminal with automatic name: 1\n",
      "[I 2025-05-10 14:08:06.429 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:08:32.950 ServerApp] Saving file at /work/ray_runtime.json\n",
      "[I 2025-05-10 14:08:33.268 ServerApp] Saving file at /work/ray_runtime.json\n",
      "[I 2025-05-10 14:08:33.502 ServerApp] Saving file at /work/ray_runtime.json\n",
      "[C 2025-05-10 14:12:34.236 ServerApp] received signal 15, stopping\n",
      "[I 2025-05-10 14:12:34.237 ServerApp] Shutting down 9 extensions\n",
      "Entered start.sh with args: start-notebook.py\n",
      "Running hooks in: /usr/local/bin/start-notebook.d as uid: 1000 gid: 100\n",
      "Done running hooks in: /usr/local/bin/start-notebook.d\n",
      "Running hooks in: /usr/local/bin/before-notebook.d as uid: 1000 gid: 100\n",
      "Sourcing shell script: /usr/local/bin/before-notebook.d/10activate-conda-env.sh\n",
      "Done running hooks in: /usr/local/bin/before-notebook.d\n",
      "Executing the command: start-notebook.py\n",
      "[I 2025-05-10 14:13:37.853 ServerApp] jupyter_lsp | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:37.855 ServerApp] jupyter_server_mathjax | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:37.858 ServerApp] jupyter_server_terminals | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:37.861 ServerApp] jupyterlab | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:37.861 ServerApp] jupyterlab_git | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:37.864 ServerApp] nbclassic | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:37.864 ServerApp] nbdime | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:37.867 ServerApp] notebook | extension was successfully linked.\n",
      "[I 2025-05-10 14:13:38.049 ServerApp] notebook_shim | extension was successfully linked.\n",
      "[W 2025-05-10 14:13:38.064 ServerApp] WARNING: The Jupyter server is listening on all IP addresses and not using encryption. This is not recommended.\n",
      "[I 2025-05-10 14:13:38.064 ServerApp] notebook_shim | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.089 ServerApp] jupyter_lsp | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.090 ServerApp] jupyter_server_mathjax | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.091 ServerApp] jupyter_server_terminals | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.093 LabApp] JupyterLab extension loaded from /opt/conda/lib/python3.12/site-packages/jupyterlab\n",
      "[I 2025-05-10 14:13:38.093 LabApp] JupyterLab application directory is /opt/conda/share/jupyter/lab\n",
      "[I 2025-05-10 14:13:38.094 LabApp] Extension Manager is 'pypi'.\n",
      "[I 2025-05-10 14:13:38.128 ServerApp] jupyterlab | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.131 ServerApp] jupyterlab_git | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.134 ServerApp] nbclassic | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.176 ServerApp] nbdime | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.180 ServerApp] notebook | extension was successfully loaded.\n",
      "[I 2025-05-10 14:13:38.180 ServerApp] Serving notebooks from local directory: /home/jovyan\n",
      "[I 2025-05-10 14:13:38.180 ServerApp] Jupyter Server 2.15.0 is running at:\n",
      "[I 2025-05-10 14:13:38.180 ServerApp] http://localhost:8888/lab?token=47a5f6b6762dcc300cc8e04a4a1839be49fbbb220eb7b881\n",
      "[I 2025-05-10 14:13:38.180 ServerApp]     http://127.0.0.1:8888/lab?token=47a5f6b6762dcc300cc8e04a4a1839be49fbbb220eb7b881\n",
      "[I 2025-05-10 14:13:38.180 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "[C 2025-05-10 14:13:38.183 ServerApp] \n",
      "    \n",
      "    To access the server, open this file in a browser:\n",
      "        file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html\n",
      "    Or copy and paste one of these URLs:\n",
      "        http://localhost:8888/lab?token=47a5f6b6762dcc300cc8e04a4a1839be49fbbb220eb7b881\n",
      "        http://127.0.0.1:8888/lab?token=47a5f6b6762dcc300cc8e04a4a1839be49fbbb220eb7b881\n",
      "[I 2025-05-10 14:13:38.209 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\n",
      "[W 2025-05-10 14:13:52.665 LabApp] Could not determine jupyterlab build status without nodejs\n",
      "[I 2025-05-10 14:13:53.592 ServerApp] New terminal with automatic name: 1\n",
      "[I 2025-05-10 14:14:19.076 ServerApp] Saving file at /work/ray_runtime.json\n",
      "[I 2025-05-10 14:14:41.992 ServerApp] Saving file at /work/ray_runtime.json\n",
      "[I 2025-05-10 14:14:44.981 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:14:49.875 ServerApp] Saving file at /work/ray_requirements.txt\n",
      "[I 2025-05-10 14:21:03.054 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:25:54.439 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:25:55.563 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:25:55.841 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:27:52.660 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:27:53.263 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:27:53.560 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:27:53.787 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:27:54.016 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:28:49.268 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:28:49.499 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:30:12.711 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:33:42.823 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:33:43.086 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:33:48.023 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:34:40.041 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:34:40.261 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:37:40.295 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:37:40.669 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:37:41.111 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:38:52.797 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:40:34.515 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:40:34.951 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:42:34.765 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:43:16.411 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:43:16.647 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:45:04.663 ServerApp] 302 GET / (@121.188.105.198) 0.80ms\n",
      "[I 2025-05-10 14:46:44.121 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:46:44.359 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:48:44.361 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:48:53.789 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:48:54.037 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:49:06.273 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:49:30.335 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:51:19.949 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:51:20.451 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:53:18.858 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:53:28.025 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:57:46.748 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:57:52.857 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:58:00.333 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:58:36.941 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 14:59:28.367 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:02:07.750 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:02:59.941 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:13:01.879 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:13:18.269 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:13:20.319 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:13:20.549 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:13:20.778 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:15:51.205 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:15:51.429 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:15:57.203 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:17:49.543 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:17:49.765 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:50:16.921 ServerApp] Saving fi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _   _          _      _\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "le at /work/train_ray.py\n",
      "[I 2025-05-10 15:50:39.744 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:50:48.832 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:51:04.991 ServerApp] Saving file at /work/ray_runtime.json\n",
      "[I 2025-05-10 15:51:05.231 ServerApp] Saving file at /work/ray_runtime.json\n",
      "[I 2025-05-10 15:51:17.236 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:52:39.976 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:52:56.017 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:52:57.246 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 15:53:04.201 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:08.940 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:09.233 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:09.457 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:11.116 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:11.416 Serv"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | | | |_ __  __| |__ _| |_ ___\n",
      " | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "  \\___/| .__/\\__,_\\__,_|\\__\\___|\n",
      "       |_|\n",
      "\n",
      "Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions.\n",
      "\n",
      "https://jupyter-notebook.readthedocs.io/en/latest/migrate_to_notebook7.html\n",
      "\n",
      "Please note that updating to Notebook 7 might break some of your extensions.\n",
      "\n",
      "Executing: jupyter lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "erApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:11.668 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:11.910 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:06:12.152 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:08:49.662 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:08:49.889 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:09:37.746 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:18:43.706 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:18:46.158 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:22:01.810 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:36:51.548 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:36:51.776 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:47:16.152 ServerApp] Saving file at /work/train_ray.py\n",
      "[I 2025-05-10 16:48:01.186 ServerApp] Saving file at /work/train_ray.py\n",
      "[C 2025-05-10 16:53:54.606 ServerApp] received signal 15, stopping\n",
      "[I 2025-05-10 16:53:54.609 ServerApp] Shutting down 9 extensions\n",
      "Entered start.sh with args: start-notebook.py\n",
      "Running hooks in: /usr/local/bin/start-notebook.d as uid: 1000 gid: 100\n",
      "Done running hooks in: /usr/local/bin/start-notebook.d\n",
      "Running hooks in: /usr/local/bin/before-notebook.d as uid: 1000 gid: 100\n",
      "Sourcing shell script: /usr/local/bin/before-notebook.d/10activate-conda-env.sh\n",
      "Done running hooks in: /usr/local/bin/before-notebook.d\n",
      "Executing the command: start-notebook.py\n",
      "[I 2025-05-10 16:56:53.220 ServerApp] jupyter_lsp | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.223 ServerApp] jupyter_server_mathjax | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.225 ServerApp] jupyter_server_terminals | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.228 ServerApp] jupyterlab | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.228 ServerApp] jupyterlab_git | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.231 ServerApp] nbclassic | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.231 ServerApp] nbdime | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.234 ServerApp] notebook | extension was successfully linked.\n",
      "[I 2025-05-10 16:56:53.412 ServerApp] notebook_shim | extension was successfully linked.\n",
      "[W 2025-05-10 16:56:53.428 ServerApp] WARNING: The Jupyter server is listening on all IP addresses and not using encryption. This is not recommended.\n",
      "[I 2025-05-10 16:56:53.428 ServerApp] notebook_shim | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.455 ServerApp] jupyter_lsp | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.456 ServerApp] jupyter_server_mathjax | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.457 ServerApp] jupyter_server_terminals | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.460 LabApp] JupyterLab extension loaded from /opt/conda/lib/python3.12/site-packages/jupyterlab\n",
      "[I 2025-05-10 16:56:53.460 LabApp] JupyterLab application directory is /opt/conda/share/jupyter/lab\n",
      "[I 2025-05-10 16:56:53.460 LabApp] Extension Manager is 'pypi'.\n",
      "[I 2025-05-10 16:56:53.497 ServerApp] jupyterlab | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.500 ServerApp] jupyterlab_git | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.503 ServerApp] nbclassic | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.544 ServerApp] nbdime | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.547 ServerApp] notebook | extension was successfully loaded.\n",
      "[I 2025-05-10 16:56:53.548 ServerApp] Serving notebooks from local directory: /home/jovyan\n",
      "[I 2025-05-10 16:56:53.548 ServerApp] Jupyter Server 2.15.0 is running at:\n",
      "[I 2025-05-10 16:56:53.548 ServerApp] http://localhost:8888/lab?token=0cd3a725660b954c03977db33e2effee1514c86eb9bd741b\n",
      "[I 2025-05-10 16:56:53.548 ServerApp]     http://127.0.0.1:8888/lab?token=0cd3a725660b954c03977db33e2effee1514c86eb9bd741b\n",
      "[I 2025-05-10 16:56:53.548 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "[C 2025-05-10 16:56:53.550 ServerApp] \n",
      "    \n",
      "    To access the server, open this file in a browser:\n",
      "        file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html\n",
      "    Or copy and paste one of these URLs:\n",
      "        http://localhost:8888/lab?token=0cd3a725660b954c03977db33e2effee1514c86eb9bd741b\n",
      "        http://127.0.0.1:8888/lab?token=0cd3a725660b954c03977db33e2effee1514c86eb9bd741b\n",
      "[I 2025-05-10 16:56:53.577 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='docker logs jupyter-ray' exited=0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.execute(\"docker logs jupyter-ray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
